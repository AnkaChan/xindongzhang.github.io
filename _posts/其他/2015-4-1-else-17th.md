---
layout: post
category: else
title: jieba 分词常见错误
---

因为后面的搜索引擎需要用到结巴分词这个开源库，所以单开了一篇博文来记录一下使用过程中所犯的错误。

### 使用jieba.cut 之后不能用来直接跟str类型进行比较，比如"我"

* 解决方法：（非常诡异，我debug了一天）:当分词的数目是1个的时候，只要将分词后的每个元素encode成utf-8就可以，但是分词的数目是多个的时候，需要encode成gbk的格式。下面的伪码中，我已经实现将分词后的结果强转成了list。

~~~
  if len(queryword) > 1:
      coding_scheme = 'gbk'
  else:
      coding_scheme = 'utf-8'
~~~

### 在SAE上配置和使用jieba分词

* 解决方法：修改jieba目录的__init__.py文件, 添加import sae将 tempfile.gettempdir() 修改为 sae.core.get_tmp_dir()，然后就可以使用了。


### SAE中关于jieba分词的import问题

* 用sys把jieba分词所在的目录给add进去就可以找到

~~~
import sys
sys.path.append('./plugins/')
import jieba
~~~

